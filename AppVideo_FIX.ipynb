{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AppVideo_FIX.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rizal476/CV2020/blob/main/AppVideo_FIX.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0Yqq8KrpRvH"
      },
      "source": [
        "# How to use:\n",
        "\n",
        "* Click This Box\n",
        "* Shift + Enter all the box\n",
        "* To stop the webcam capture, click red text or the picture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAWZTcvf2O7L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07bdf3a6-534f-422f-90e9-f0f8eb3f0549"
      },
      "source": [
        "!pip install face-alignment"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: face-alignment in /usr/local/lib/python3.6/dist-packages (1.1.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from face-alignment) (0.16.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from face-alignment) (1.7.0+cu101)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from face-alignment) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from face-alignment) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.6/dist-packages (from face-alignment) (1.4.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from face-alignment) (4.1.2.30)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->face-alignment) (1.1.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->face-alignment) (2.4.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->face-alignment) (7.0.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->face-alignment) (3.2.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->face-alignment) (2.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->face-alignment) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->face-alignment) (0.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->face-alignment) (3.7.4.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment) (0.10.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image->face-alignment) (4.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJHeMmFR2t1s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f3bc7ef-318e-410b-b149-cda2643385d0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OYmjeF-edKE"
      },
      "source": [
        "import base64\n",
        "import html\n",
        "import io\n",
        "import time\n",
        "import face_alignment\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "def start_input():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "    \n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "    \n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "    \n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 512, 512);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "    \n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "      \n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "           \n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "      \n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML = \n",
        "          '<span style=\"color: red; font-weight: bold;\">' +\n",
        "          'When finished, click here or on the video to stop this demo</span>';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "      \n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 512; //video.videoWidth;\n",
        "      captureCanvas.height = 512; //video.videoHeight;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "      \n",
        "      return stream;\n",
        "    }\n",
        "    async function takePhoto(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "      \n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "            \n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "      \n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "      \n",
        "      return {'create': preShow - preCreate, \n",
        "              'show': preCapture - preShow, \n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "  \n",
        "def take_photo(label, img_data):\n",
        "  data = eval_js('takePhoto(\"{}\", \"{}\")'.format(label, img_data))\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ircKOxyp0fZK"
      },
      "source": [
        "#get all face coordinates using Face Alignment\n",
        "def getFaceCoordinate(img):\n",
        "  cv2_im = cv2.cvtColor(img,cv2.COLOR_BGR2RGB) #convert img color\n",
        "  fa = face_alignment.FaceAlignment(face_alignment.LandmarksType._2D, flip_input=True) #load Face Alignment\n",
        "  preds = fa.get_landmarks(cv2_im)[-1] #get all face coordinates\n",
        "  \n",
        "  return preds #return all face coordinates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q506nlys1Eba"
      },
      "source": [
        "#calculate euclidean distance for 8 fix points\n",
        "def hitung_euclidean(koordinat):\n",
        "  distance = []\n",
        "  for i in range(len(koordinat)): #looping for the 8 points\n",
        "    for j in range(i): \n",
        "      distance.append(np.linalg.norm(koordinat[i]-koordinat[j])) #save the euclidean distances between two points\n",
        "  return np.array(distance) #return all euclidean distances"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0ZgJiQBskDt"
      },
      "source": [
        "import argparse\n",
        "from sys import platform\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model_prediksi = load_model('/content/drive/My Drive/FG/train 7 oktober 2020/model_lstm_rizal_10 oktober 2020 6:02pm.h5') #load model \n",
        "buffer = [] #to store frames\n",
        "\n",
        "#conver from js object (camera) to image numpy array\n",
        "def js_object_to_img_array(js_reply):\n",
        "    \"\"\"\n",
        "    input: \n",
        "          js_reply: JavaScript object, contain image from webcam\n",
        "\n",
        "    output: \n",
        "          image_array: image array RGB size 512 x 512 from webcam\n",
        "    \"\"\"\n",
        "    jpeg_bytes = base64.b64decode(js_reply['img'].split(',')[1])\n",
        "    image_PIL = Image.open(io.BytesIO(jpeg_bytes)) #open image using Image PIL\n",
        "    image_array = np.array(image_PIL) #change to numpy array\n",
        "\n",
        "    return image_array #return image (numpy array)\n",
        "\n",
        "#classifying image\n",
        "def classifying_img(image_array): \n",
        "    faceCoor = getFaceCoordinate(image_array) #get all face coordinates\n",
        "    fix_index = [8, 2, 14, 30, 48, 54] #the determined 8 fix points index for face\n",
        "    faceCoorFix = [faceCoor[x] for x in fix_index ] #get the 8 fix points\n",
        "    faceCoorFix = hitung_euclidean(faceCoorFix) #calculate the euclidean distaces for all points\n",
        "    if len(buffer) == 40: #if buffer contains 40 frames\n",
        "        buffer.pop(0) #pop 1 frame\n",
        "\n",
        "    buffer.append(faceCoorFix) #store euclidean distances for 8 points\n",
        "    y_pred = -1\n",
        "    if len(buffer) == 40: #if buffer contains 40 frames\n",
        "      buffer2 = np.array(buffer)\n",
        "      buffer2 = np.expand_dims(buffer2,0)\n",
        "      y_pred = model_prediksi.predict(buffer2) #predict using the euclidean distances\n",
        "      print(np.round(y_pred, 3)) \n",
        "\n",
        "    return y_pred #return predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIlKEQ3ruDCw"
      },
      "source": [
        "# Try Webcam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZi6NXSDyAY6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "outputId": "ea19ee72-8f63-4822-ba0e-b1cf78d137ba"
      },
      "source": [
        "start_input()\n",
        "label_html = 'Capturing...'\n",
        "img_data = ''\n",
        "\n",
        "while True:\n",
        "  js_reply = take_photo(label_html, img_data)\n",
        "  if not js_reply:\n",
        "    break\n",
        "  image = js_object_to_img_array(js_reply)\n",
        "  y_pred= classifying_img(image)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    var video;\n",
              "    var div = null;\n",
              "    var stream;\n",
              "    var captureCanvas;\n",
              "    var imgElement;\n",
              "    var labelElement;\n",
              "    \n",
              "    var pendingResolve = null;\n",
              "    var shutdown = false;\n",
              "    \n",
              "    function removeDom() {\n",
              "       stream.getVideoTracks()[0].stop();\n",
              "       video.remove();\n",
              "       div.remove();\n",
              "       video = null;\n",
              "       div = null;\n",
              "       stream = null;\n",
              "       imgElement = null;\n",
              "       captureCanvas = null;\n",
              "       labelElement = null;\n",
              "    }\n",
              "    \n",
              "    function onAnimationFrame() {\n",
              "      if (!shutdown) {\n",
              "        window.requestAnimationFrame(onAnimationFrame);\n",
              "      }\n",
              "      if (pendingResolve) {\n",
              "        var result = \"\";\n",
              "        if (!shutdown) {\n",
              "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 512, 512);\n",
              "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
              "        }\n",
              "        var lp = pendingResolve;\n",
              "        pendingResolve = null;\n",
              "        lp(result);\n",
              "      }\n",
              "    }\n",
              "    \n",
              "    async function createDom() {\n",
              "      if (div !== null) {\n",
              "        return stream;\n",
              "      }\n",
              "\n",
              "      div = document.createElement('div');\n",
              "      div.style.border = '2px solid black';\n",
              "      div.style.padding = '3px';\n",
              "      div.style.width = '100%';\n",
              "      div.style.maxWidth = '600px';\n",
              "      document.body.appendChild(div);\n",
              "      \n",
              "      const modelOut = document.createElement('div');\n",
              "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
              "      labelElement = document.createElement('span');\n",
              "      labelElement.innerText = 'No data';\n",
              "      labelElement.style.fontWeight = 'bold';\n",
              "      modelOut.appendChild(labelElement);\n",
              "      div.appendChild(modelOut);\n",
              "           \n",
              "      video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      video.width = div.clientWidth - 6;\n",
              "      video.setAttribute('playsinline', '');\n",
              "      video.onclick = () => { shutdown = true; };\n",
              "      stream = await navigator.mediaDevices.getUserMedia(\n",
              "          {video: { facingMode: \"environment\"}});\n",
              "      div.appendChild(video);\n",
              "\n",
              "      imgElement = document.createElement('img');\n",
              "      imgElement.style.position = 'absolute';\n",
              "      imgElement.style.zIndex = 1;\n",
              "      imgElement.onclick = () => { shutdown = true; };\n",
              "      div.appendChild(imgElement);\n",
              "      \n",
              "      const instruction = document.createElement('div');\n",
              "      instruction.innerHTML = \n",
              "          '<span style=\"color: red; font-weight: bold;\">' +\n",
              "          'When finished, click here or on the video to stop this demo</span>';\n",
              "      div.appendChild(instruction);\n",
              "      instruction.onclick = () => { shutdown = true; };\n",
              "      \n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      captureCanvas = document.createElement('canvas');\n",
              "      captureCanvas.width = 512; //video.videoWidth;\n",
              "      captureCanvas.height = 512; //video.videoHeight;\n",
              "      window.requestAnimationFrame(onAnimationFrame);\n",
              "      \n",
              "      return stream;\n",
              "    }\n",
              "    async function takePhoto(label, imgData) {\n",
              "      if (shutdown) {\n",
              "        removeDom();\n",
              "        shutdown = false;\n",
              "        return '';\n",
              "      }\n",
              "\n",
              "      var preCreate = Date.now();\n",
              "      stream = await createDom();\n",
              "      \n",
              "      var preShow = Date.now();\n",
              "      if (label != \"\") {\n",
              "        labelElement.innerHTML = label;\n",
              "      }\n",
              "            \n",
              "      if (imgData != \"\") {\n",
              "        var videoRect = video.getClientRects()[0];\n",
              "        imgElement.style.top = videoRect.top + \"px\";\n",
              "        imgElement.style.left = videoRect.left + \"px\";\n",
              "        imgElement.style.width = videoRect.width + \"px\";\n",
              "        imgElement.style.height = videoRect.height + \"px\";\n",
              "        imgElement.src = imgData;\n",
              "      }\n",
              "      \n",
              "      var preCapture = Date.now();\n",
              "      var result = await new Promise(function(resolve, reject) {\n",
              "        pendingResolve = resolve;\n",
              "      });\n",
              "      shutdown = false;\n",
              "      \n",
              "      return {'create': preShow - preCreate, \n",
              "              'show': preCapture - preShow, \n",
              "              'capture': Date.now() - preCapture,\n",
              "              'img': result};\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[[1.2425653e-04 6.3547236e-07 3.6043103e-03 2.6952026e-03 9.9357563e-01]]\n",
            "[[3.1854496e-03 9.9156946e-01 5.1368014e-03 2.4668037e-05 8.3571322e-05]]\n",
            "[[4.1535329e-03 9.5581836e-01 3.9958082e-02 6.8936453e-05 9.9932060e-07]]\n",
            "[[4.4973241e-03 4.4707934e-04 1.9353710e-01 8.0139071e-01 1.2777165e-04]]\n",
            "[[2.6366243e-03 2.1700826e-06 6.8859110e-04 9.9612075e-01 5.5181014e-04]]\n",
            "[[2.3850633e-01 2.3784185e-06 5.0654111e-04 7.4724662e-01 1.3738190e-02]]\n",
            "[[7.1845627e-03 5.6148639e-07 1.0455427e-02 9.8009723e-01 2.2621895e-03]]\n",
            "[[1.0438766e-02 3.5074146e-07 3.9778589e-04 9.8152268e-01 7.6403590e-03]]\n",
            "[[1.6874027e-04 8.9412475e-07 3.0975381e-04 7.9153836e-01 2.0798218e-01]]\n",
            "[[1.1851051e-02 9.3215766e-07 4.7683958e-03 9.3353236e-01 4.9847320e-02]]\n",
            "[[6.2794625e-03 6.5331699e-07 3.2520974e-03 9.8277032e-01 7.6975157e-03]]\n",
            "[[5.1875077e-02 1.7029660e-06 2.5071612e-02 9.0402901e-01 1.9022550e-02]]\n",
            "[[1.8240776e-02 9.1054164e-05 4.2490275e-03 4.4294526e-03 9.7298968e-01]]\n",
            "[[1.6488643e-02 9.0890309e-05 2.1357168e-02 6.2897238e-03 9.5577359e-01]]\n",
            "[[4.2421851e-01 2.4338164e-04 3.8938317e-01 2.8565128e-03 1.8329839e-01]]\n",
            "[[1.3115986e-03 1.2908338e-06 1.7396293e-03 3.4092736e-05 9.9691331e-01]]\n",
            "[[2.0943911e-05 1.7174251e-07 6.5042538e-04 5.5216702e-07 9.9932790e-01]]\n",
            "[[1.7257218e-04 1.5769916e-05 3.9915224e-03 1.4265748e-05 9.9580586e-01]]\n",
            "[[4.4209187e-06 6.4706285e-07 5.6386530e-06 1.0405848e-06 9.9998820e-01]]\n",
            "[[9.9370743e-07 3.2115373e-08 4.7831446e-07 2.8293283e-07 9.9999821e-01]]\n",
            "[[1.8037633e-07 1.3800130e-09 2.4185281e-08 5.2753013e-08 9.9999976e-01]]\n",
            "[[7.1478468e-07 4.2500080e-08 4.1706187e-07 7.6979141e-08 9.9999881e-01]]\n",
            "[[2.1836446e-07 3.4117755e-09 5.7686439e-08 1.3109816e-08 9.9999976e-01]]\n",
            "[[1.1522390e-06 8.5124103e-09 1.9587949e-06 2.3919045e-08 9.9999690e-01]]\n",
            "[[7.9789459e-07 5.2613604e-08 1.9170054e-06 9.5970542e-08 9.9999714e-01]]\n",
            "[[2.7120202e-06 8.9023246e-08 1.5388065e-06 3.9413155e-07 9.9999523e-01]]\n",
            "[[3.5380483e-06 4.9312268e-07 5.5058031e-06 1.1053218e-06 9.9998939e-01]]\n",
            "[[3.2877062e-06 4.6991678e-07 1.0139594e-05 4.5796253e-07 9.9998569e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Hfo6lqZEaQy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}